{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ref reg_SVM_logit_LSTM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Python Environment\n",
    "    Import Dataset\n",
    "    Test Setup\n",
    "    Persistence Model Forecast\n",
    "    LSTM Data Preparation\n",
    "    LSTM Model Development\n",
    "    LSTM Forecast\n",
    "    Complete LSTM Example\n",
    "    Develop a Robust Result\n",
    "    Tutorial Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.DataFrame()\n",
    "pdf= pd.DataFrame()\n",
    "\n",
    "def get_csv_pd(path):\n",
    "    #spy_pd=pd.read_csv('C:\\\\Users\\Michal\\Dropbox\\IB_data\\SPY.csv',sep=' ',names=['askPrice','askSize','bidPrice','bidSize'],index_col=0,parse_dates=True)\n",
    "    #spy_pd=pd.read_csv(path+'\\SPY.csv',sep=',',names=['askPrice','askSize','bidPrice','bidSize'],index_col=0,parse_dates=True)\n",
    "    spy_pd=pd.read_csv(path,sep=',',dtype={'askPrice':np.float32,'askSize':np.float32,\n",
    "                                           'bidPrice':np.float32,'bidSize':np.float32},index_col=0,parse_dates=True)\n",
    "    return spy_pd\n",
    "\n",
    "def get_csv_pd_notime(path):\n",
    "    #spy_pd=pd.read_csv('C:\\\\Users\\Michal\\Dropbox\\IB_data\\SPY.csv',sep=' ',names=['askPrice','askSize','bidPrice','bidSize'],index_col=0,parse_dates=True)\n",
    "    #spy_pd=pd.read_csv(path+'\\SPY.csv',sep=',',names=['askPrice','askSize','bidPrice','bidSize'],index_col=0,parse_dates=True)\n",
    "    spy_pd = pd.read_csv(path, usecols=['askPrice','askSize','bidPrice','bidSize'], engine='python', skipfooter=3)\n",
    "    return spy_pd\n",
    "def preprocessing_df(df):\n",
    "    df.bidPrice=df.bidPrice.replace(to_replace=0, method='ffill')\n",
    "    df.bidSize=df.bidSize.replace(to_replace=0, method='ffill')\n",
    "    df.askPrice=df.askPrice.replace(to_replace=0, method='ffill')\n",
    "    df.askSize=df.askSize.replace(to_replace=0, method='ffill')\n",
    "    df['Close']=(df.bidPrice+df.askPrice)/2\n",
    "    df['price']=(df.bidPrice*df.bidSize+df.askPrice*df.askSize)/(df.bidSize+df.askSize)\n",
    "    #velP=np.where(df.Close>df.Close.shift(60),1,0)\n",
    "    #velN=np.where(df.Close<df.Close.shift(60),-1,0)\n",
    "    #U=np.where(df.Close>df.price.rolling(60).max(),1,0)\n",
    "    #D=np.where(df.Close<df.price.rolling(60).max(),-1,0)\n",
    "    #df['U']= np.where(velP*U==1,1,0)\n",
    "    #df['D']= np.where(velN*D==1,-1,0)\n",
    "    #df['U']= np.where(velP==1,1,0)\n",
    "    #df['D']= np.where(velN==1,-1,0)\n",
    "    df['U']= np.where(df.Close>df.price,1,0)\n",
    "    df['D']= np.where(df.Close<df.price,-1,0)\n",
    "    df['log']=np.log(df.Close)\n",
    "    #df['logDiff'] = df.log-df.log.rolling(60).mean()# almost 1 min\n",
    "    df['logDiff'] = df.log-df.log.shift(60)# almost 1 min\n",
    "    df['sigma']=df.log.rolling(60).std()\n",
    "    return df\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    " \n",
    "# monkey patch around bug in ARIMA class\n",
    "def __getnewargs__(self):\n",
    "\treturn ((self.endog),(self.k_lags, self.k_diff, self.k_ma))\n",
    "ARIMA.__getnewargs__ = __getnewargs__\n",
    "\n",
    "\n",
    "def ARIMA_df(df):\n",
    "    data=df.logDiff.dropna()\n",
    "    model = ARIMA(data, order=(2,1,2))  # tested from ARIMA.ipynb\n",
    "    #predictions = model.fit(disp=0).predict()\n",
    "    predictions =model.fit(disp=0).fittedvalues\n",
    "    # save model\n",
    "    model.fit().save('sevennine_arima.pkl')\n",
    "    df['pr_arima']=np.exp(predictions+df.log.rolling(60).mean())\n",
    "    return df\n",
    "\n",
    "# Import a Kalman filter and other useful libraries\n",
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import poly1d\n",
    "\n",
    "def kalman_ma(data):\n",
    "    x=data.price.tail(60)\n",
    "    y=data.Close.tail(60)\n",
    "    # Construct a Kalman filter\n",
    "    kf = KalmanFilter(transition_matrices = [1],\n",
    "                  observation_matrices = [1],\n",
    "                  initial_state_mean = 246,\n",
    "                  initial_state_covariance = 1,\n",
    "                  observation_covariance=1,\n",
    "                  transition_covariance=.01)\n",
    "\n",
    "    # Use the observed values of the price to get a rolling mean\n",
    "    state_means, _ = kf.filter(x.values)\n",
    "    state_means = pd.Series(state_means.flatten(), index=x.index)\n",
    "    data['km']=state_means\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path = 'C:\\\\Users\\Michal\\Dropbox\\IB_data'\n",
    "#path = 'C:\\\\Users\\Michal\\Desktop'+ '\\SPY14Aug17.csv'\n",
    "path = '/home/octo/Dropbox'+ '/SPY15Aug17.csv'\n",
    "df1=get_csv_pd_notime(path)\n",
    "df=get_csv_pd(path)\n",
    "df=df[500:15500]\n",
    "df=preprocessing_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=ARIMA_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>askPrice</th>\n",
       "      <th>askSize</th>\n",
       "      <th>bidPrice</th>\n",
       "      <th>bidSize</th>\n",
       "      <th>Close</th>\n",
       "      <th>price</th>\n",
       "      <th>U</th>\n",
       "      <th>D</th>\n",
       "      <th>log</th>\n",
       "      <th>logDiff</th>\n",
       "      <th>sigma</th>\n",
       "      <th>pr_arima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-14 11:24:53.702647</th>\n",
       "      <td>246.529999</td>\n",
       "      <td>49.0</td>\n",
       "      <td>246.520004</td>\n",
       "      <td>47.0</td>\n",
       "      <td>246.524994</td>\n",
       "      <td>246.525101</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.507463</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>246.521014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14 11:24:53.889651</th>\n",
       "      <td>246.529999</td>\n",
       "      <td>64.0</td>\n",
       "      <td>246.520004</td>\n",
       "      <td>47.0</td>\n",
       "      <td>246.524994</td>\n",
       "      <td>246.525757</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.507463</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>246.521514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14 11:24:55.384690</th>\n",
       "      <td>246.529999</td>\n",
       "      <td>64.0</td>\n",
       "      <td>246.520004</td>\n",
       "      <td>54.0</td>\n",
       "      <td>246.524994</td>\n",
       "      <td>246.525421</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.507463</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>246.522015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14 11:24:55.577695</th>\n",
       "      <td>246.529999</td>\n",
       "      <td>58.0</td>\n",
       "      <td>246.520004</td>\n",
       "      <td>54.0</td>\n",
       "      <td>246.524994</td>\n",
       "      <td>246.525177</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.507463</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>246.522514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14 11:24:55.769700</th>\n",
       "      <td>246.529999</td>\n",
       "      <td>49.0</td>\n",
       "      <td>246.520004</td>\n",
       "      <td>54.0</td>\n",
       "      <td>246.524994</td>\n",
       "      <td>246.524765</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.507463</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>246.522931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              askPrice  askSize    bidPrice  bidSize  \\\n",
       "2017-08-14 11:24:53.702647  246.529999     49.0  246.520004     47.0   \n",
       "2017-08-14 11:24:53.889651  246.529999     64.0  246.520004     47.0   \n",
       "2017-08-14 11:24:55.384690  246.529999     64.0  246.520004     54.0   \n",
       "2017-08-14 11:24:55.577695  246.529999     58.0  246.520004     54.0   \n",
       "2017-08-14 11:24:55.769700  246.529999     49.0  246.520004     54.0   \n",
       "\n",
       "                                 Close       price  U  D       log   logDiff  \\\n",
       "2017-08-14 11:24:53.702647  246.524994  246.525101  0 -1  5.507463  0.000122   \n",
       "2017-08-14 11:24:53.889651  246.524994  246.525757  0 -1  5.507463  0.000122   \n",
       "2017-08-14 11:24:55.384690  246.524994  246.525421  0 -1  5.507463  0.000122   \n",
       "2017-08-14 11:24:55.577695  246.524994  246.525177  0 -1  5.507463  0.000122   \n",
       "2017-08-14 11:24:55.769700  246.524994  246.524765  1  0  5.507463  0.000102   \n",
       "\n",
       "                               sigma    pr_arima  \n",
       "2017-08-14 11:24:53.702647  0.000037  246.521014  \n",
       "2017-08-14 11:24:53.889651  0.000034  246.521514  \n",
       "2017-08-14 11:24:55.384690  0.000031  246.522015  \n",
       "2017-08-14 11:24:55.577695  0.000027  246.522514  \n",
       "2017-08-14 11:24:55.769700  0.000025  246.522931  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### load model\n",
    "#loaded = ARIMAResults.load('sevennine_arima.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=kalman_ma(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# saving linear model\n",
    "df=df.dropna()\n",
    "X=df[['askPrice','askSize','bidPrice','bidSize','Close','pr_arima','U','D','sigma']]\n",
    "y=df[['logDiff']]\n",
    "regr = linear_model.LinearRegression()\n",
    "regr_model=regr.fit(X,y)\n",
    "regr_model = pickle.dumps(regr_model)\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.9) #kernel='linear' #kernel='poly'\n",
    "svr_model = svr_rbf.fit(X, y)\n",
    "svr_model = pickle.dumps(svr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# saving logistics and SVC model\n",
    "df=df.dropna()\n",
    "X=df[['askPrice','askSize','bidPrice','bidSize','Close','price','pr_arima','sigma']]\n",
    "y1=df[['U']]\n",
    "y2=df[['D']]\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "lm = linear_model.LogisticRegression(C=1e4)\n",
    "svm_model_up= svm.fit(X,y1)\n",
    "svm_model_up = pickle.dumps(svm_model_up)\n",
    "lm_model_up= lm.fit(X, y1)\n",
    "lm_model_up = pickle.dumps(lm_model_up)\n",
    "svm_model_dn= svm.fit(X, y2)\n",
    "svm_model_dn = pickle.dumps(svm_model_dn)\n",
    "lm_model_dn= lm.fit(X, y2)\n",
    "lm_model_dn = pickle.dumps(lm_model_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading regression model, first save the model\n",
    "svr_model = pickle.loads(svr_model)\n",
    "regr_model = pickle.loads(regr_model)\n",
    "\n",
    "#loading classification model, first save the model\n",
    "svm_model_up = pickle.loads(svm_model_up)\n",
    "svm_model_dn = pickle.loads(svm_model_dn)\n",
    "lm_model_up = pickle.loads(lm_model_up)\n",
    "lm_model_dn = pickle.loads(lm_model_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strat_lr(data):\n",
    "    data=data.tail(60).dropna()\n",
    "    X=data[['askPrice','askSize','bidPrice','bidSize','Close','pr_arima','U','D','sigma']]\n",
    "    y=data[['logDiff']]\n",
    "    predict_regr=regr_model.predict(X)\n",
    "    predict_svr=svr_model.predict(X)\n",
    "    dt=data[['Close']]\n",
    "    dt['predict_regr']=predict_regr\n",
    "    dt['predict_svr']=predict_svr\n",
    "        \n",
    "    pdf=data\n",
    "    pdf['pREG']=np.exp(dt.predict_regr+data.log.shift(59))\n",
    "    pdf['pSVR']=np.exp(dt.predict_regr+data.log.shift(59))\n",
    "         \n",
    "    #dt=data[['price','predict']]\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df=strat_lr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_up_dn(data):\n",
    "    X=data[['askPrice','askSize','bidPrice','bidSize','Close','price','pr_arima','sigma']]\n",
    "    y1=data[['U']]\n",
    "    y2=data[['D']]\n",
    "    pr_df=data.tail(60)\n",
    "    predict_svm_up=svm_model_up.predict(X.tail(60))\n",
    "    pr_df['predict_svm_up']=predict_svm_up\n",
    "    predict_lm_up=lm_model_up.predict(X.tail(60))\n",
    "    pr_df['predict_lm_up']=predict_lm_up\n",
    "    predict_svm_dn=svm_model_dn.predict(X.tail(60))\n",
    "    pr_df['predict_svm_dn']=predict_svm_dn\n",
    "    predict_lm_dn=lm_model_dn.predict(X.tail(60))\n",
    "    pr_df['predict_lm_dn']=predict_lm_dn\n",
    "    pr_df['predict_svm']=pr_df.predict_svm_up+pr_df.predict_svm_dn\n",
    "    pr_df['predict_lm']=pr_df.predict_lm_up+pr_df.predict_lm_dn\n",
    "    return pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df=classification_up_dn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['predict_svm']=df.predict_svm_up+df.predict_svm_dn\n",
    "df['predict_lm']=df.predict_lm_up+df.predict_lm_dn\n",
    "df['UD']=np.where(df.predict_svm+df.predict_lm>0,1,np.where(df.predict_svm+df.predict_lm,-1,0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Newly loading for longdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = 'C:\\\\Users\\Michal\\Dropbox\\IB_data'\n",
    "#path = 'C:\\\\Users\\Michal\\Desktop'+ '\\SPY14Aug17.csv'\n",
    "path = '/home/octo/Dropbox'+ '/SPY15Aug17.csv'\n",
    "df1=get_csv_pd_notime(path)\n",
    "df=get_csv_pd(path)\n",
    "df=df[500:45500]\n",
    "df=preprocessing_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=ARIMA_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['spread']=df.Close-df.pr_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset= df[['askPrice','askSize','bidPrice','bidSize','Close','spread','pr_arima','sigma']]\n",
    "dataset=dataset.dropna()\n",
    "dataset=dataset.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44939"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35951 8988\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.80)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        b = dataset[i:(i+look_back), 1]\n",
    "        c = dataset[i:(i+look_back), 2]\n",
    "        d = dataset[i:(i+look_back), 3]\n",
    "        e=  dataset[i:(i+look_back), 4]\n",
    "        f = dataset[i:(i+look_back), 5]\n",
    "        g=  dataset[i:(i+look_back), 6]\n",
    "        h=  dataset[i:(i+look_back), 7]\n",
    "        dataX.append(np.c_[a,b,c,d,f,g,h])\n",
    "        #dataX.append(b)\n",
    "        #dataX.append(c)\n",
    "        #dataX.append(d)\n",
    "        #dataX.append(e)\n",
    "        #dataX.concatenate((a,bT,cT,dT,eT),axis=1)\n",
    "        dataY.append(dataset[i + look_back,4])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train,look_back)\n",
    "testX, testY = create_dataset(test,look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0],trainX.shape[1],trainX.shape[2]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0],testX.shape[1],testX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=3\n",
    "batch_size=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24s - loss: 0.0018\n",
      "Epoch 2/25\n",
      "24s - loss: 1.8888e-05\n",
      "Epoch 3/25\n",
      "24s - loss: 1.5021e-05\n",
      "Epoch 4/25\n",
      "27s - loss: 1.3375e-05\n",
      "Epoch 5/25\n",
      "29s - loss: 1.2357e-05\n",
      "Epoch 6/25\n",
      "29s - loss: 1.1432e-05\n",
      "Epoch 7/25\n",
      "33s - loss: 1.0977e-05\n",
      "Epoch 8/25\n",
      "31s - loss: 1.0838e-05\n",
      "Epoch 9/25\n",
      "31s - loss: 1.0328e-05\n",
      "Epoch 10/25\n",
      "31s - loss: 9.9659e-06\n",
      "Epoch 11/25\n",
      "31s - loss: 9.9224e-06\n",
      "Epoch 12/25\n",
      "31s - loss: 9.6704e-06\n",
      "Epoch 13/25\n",
      "31s - loss: 9.4364e-06\n",
      "Epoch 14/25\n",
      "31s - loss: 9.5454e-06\n",
      "Epoch 15/25\n",
      "31s - loss: 9.2212e-06\n",
      "Epoch 16/25\n",
      "31s - loss: 9.1803e-06\n",
      "Epoch 17/25\n",
      "31s - loss: 9.2058e-06\n",
      "Epoch 18/25\n",
      "31s - loss: 9.0244e-06\n",
      "Epoch 19/25\n",
      "31s - loss: 8.9191e-06\n",
      "Epoch 20/25\n",
      "32s - loss: 8.6847e-06\n",
      "Epoch 21/25\n",
      "32s - loss: 8.7769e-06\n",
      "Epoch 22/25\n",
      "32s - loss: 8.6767e-06\n",
      "Epoch 23/25\n",
      "35s - loss: 8.6899e-06\n",
      "Epoch 24/25\n",
      "32s - loss: 8.6722e-06\n",
      "Epoch 25/25\n",
      "35s - loss: 8.5339e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6ce5fbcf8>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back,7)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs, batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"sevensep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
